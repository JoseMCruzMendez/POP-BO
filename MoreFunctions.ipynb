{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-26T19:49:45.664772Z",
     "start_time": "2025-02-26T19:49:44.069762Z"
    }
   },
   "source": [
    "import botorch\n",
    "import numpy as np\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.models import SingleTaskGP\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:49:45.671385Z",
     "start_time": "2025-02-26T19:49:45.665948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rastigrin(x):\n",
    "    \"x should be a tensor of shape(batch, n)\"\n",
    "    d = x.shape[-1]\n",
    "    return 10*d + (x**2 - 10*torch.cos(2*torch.pi*x)).sum(axis=-1)\n",
    "\n",
    "def michalewicz(x, m=10):\n",
    "    indices = torch.arange(start=1, end=1+x.shape[-1])\n",
    "    return -(torch.sin(x)*torch.sin(indices * x**2 / torch.pi)**(2*m)).sum(axis=-1)\n",
    "\n",
    "def six_hump(X):\n",
    "    if len(X.shape) >= 2:\n",
    "        x = X[:,0]\n",
    "        y = X[:,1]\n",
    "    else:\n",
    "        x = X[0]\n",
    "        y = X[1]\n",
    "    return ((4 - 2.1*x**2 + x**4 / 3)*x**2 + x*y + (-4+4*y**2)*y**2).squeeze()\n",
    "\n",
    "def bukin6(X):\n",
    "    if len(X.shape) >= 2:\n",
    "        x = X[:,0]\n",
    "        y = X[:,1]\n",
    "    else:\n",
    "        x = X[0]\n",
    "        y = X[1]\n",
    "    return 100 * torch.sqrt(torch.abs(y-0.01*x**2))+ 0.01*torch.abs(x+10)\n",
    "\n",
    "def mccormick(X):\n",
    "    if len(X.shape) >= 2:\n",
    "        x = X[:,0]\n",
    "        y = X[:,1]\n",
    "    else:\n",
    "        x = X[0]\n",
    "        y = X[1]\n",
    "    return torch.sin(x+y) + (x-y)**2 - 1.5*x +2.5*y +1\n",
    "\n",
    "def sum_squares(X):\n",
    "    indices = torch.arange(start=1, end=1+X.shape[-1])\n",
    "    return (indices * X).sum(axis=-1)\n",
    "\n",
    "def styblinski_tang(X):\n",
    "    return 0.5 * (X**4 - 16*X**2 + 5*X).sum(axis=-1)\n",
    "\n",
    "def goldstein_price(X):\n",
    "    if len(X.shape) >= 2:\n",
    "        x1 = X[:,0]\n",
    "        x2 = X[:,1]\n",
    "    else:\n",
    "        x1 = X[0]\n",
    "        x2 = X[1]\n",
    "    term1 = 1 + (x1 + x2 + 1)**2 * (19 - 14*x1 + 3*x1**2 - 14*x2 + 6*x1*x2 + 3*x2**2)\n",
    "    term2 = 30 + (2*x1 - 3*x2)**2 * (18 - 32*x1 + 12*x1**2 + 48*x2 - 36*x1*x2 + 27*x2**2)\n",
    "    return term1 * term2"
   ],
   "id": "8ef76720b14ec8b2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:49:45.675171Z",
     "start_time": "2025-02-26T19:49:45.672125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Function_Wrapper:\n",
    "    def __init__(self, function, name, bounds, maximum):\n",
    "        self.function = function\n",
    "        self.name = name\n",
    "        self.bounds = bounds\n",
    "        self.maximum = maximum\n",
    "        \n",
    "Rastigrin = Function_Wrapper(rastigrin, \"Rastigrin\", [[-5.12,-5.12],[5.12,5.12]], 0.)\n",
    "Michalewicz = Function_Wrapper(michalewicz, \"Michalewicz\", [[0., 0.],[torch.pi,torch.pi]], 9.66015)\n",
    "Six_Hump = Function_Wrapper(six_hump, \"Six_Hump\", [[-3.,-2.],[3.,2.]], 1.0316)\n",
    "Bukin6 = Function_Wrapper(bukin6, \"Bukin6\", [[-15.,-5.],[-3.,3.]], 0.)\n",
    "McCormick = Function_Wrapper(mccormick, \"McCormick\", [[-1.5,-3.],[4.,4.]], 1.9133)\n",
    "SumSquares = Function_Wrapper(sum_squares, \"SumSquares\", [[-10.,-10.],[10.,10.]], 0)\n",
    "StyblinskiTang = Function_Wrapper(styblinski_tang, \"StyblinskiTang\", [[-5.,-5.],[5.,5.]], 39.16599*2)\n",
    "GoldsteinPrice = Function_Wrapper(goldstein_price, \"GoldsteinPrice\", [[-2.,-2.],[2.,2.]], -3.)"
   ],
   "id": "77b368b843d654da",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a10e5565295b9e1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:49:45.682650Z",
     "start_time": "2025-02-26T19:49:45.675813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_frame(frames, function_plot, X, Y, model, init_y, beta, i, regret, name, grid):\n",
    "    #Finding max up to current iterations, to add to plot label\n",
    "    max_arg = torch.argmax(init_y)\n",
    "    y_val = init_y.squeeze(0)[max_arg].numpy().tolist()[0]\n",
    "    x_val = model.train_inputs[0][max_arg].numpy().tolist()\n",
    "    #Plotting figure first\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10,5), constrained_layout=True)\n",
    "    ax = fig.add_subplot(121, projection='3d')\n",
    "    ax.plot_surface(X, Y, function_plot, cmap=\"hot\", alpha=0.2, label=\"Objective Function\")\n",
    "    ax.scatter(model.train_inputs[0][:-1,0], model.train_inputs[0][:-1,1], init_y[:-1].squeeze(), label=\"previous point\")\n",
    "    ax.plot_wireframe(X, Y, (model(grid).mean + np.sqrt(beta) * model(grid).stddev).detach().numpy().reshape(X.shape), alpha=0.1, color = 'g', label=r'Acquisition Function')\n",
    "    ax.scatter(model.train_inputs[0][-1:,0], model.train_inputs[0][-1:,1], init_y[-1:].squeeze(), label=\"current points\", color='r')\n",
    "    ax.legend()\n",
    "    #now plot regret\n",
    "    axs[1].plot(np.array(regret).cumsum())\n",
    "    ax.set_title(name)\n",
    "    axs[1].set_title(\"Regret\")\n",
    "    fig.suptitle(f\"t = {i}, min = {y_val:.4f} at {x_val[0]:.2f}, {x_val[1]:.2f}\")\n",
    "    #axs[1].plot(np.sqrt(np.arange(1, len(regret) + 1) * np.log(np.arange(1, len(regret) + 1))**3))\n",
    "    # Save the plot to a BytesIO buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    # Convert buffer to PIL Image and store in frames\n",
    "    frames.append(Image.open(buf))\n",
    "    plt.close(fig)  # Close the plot to save memory\n",
    "    #Preparing model for next loop\n",
    "\n",
    "def make_graph(Wrapper: Function_Wrapper, beta_coeff, frame_num = 60):\n",
    "    objective_function = lambda x: -Wrapper.function(x)\n",
    "    #First, set up grid and plot function\n",
    "    X = torch.linspace(Wrapper.bounds[0][0], Wrapper.bounds[1][0], 100)\n",
    "    Y = torch.linspace(Wrapper.bounds[0][1], Wrapper.bounds[1][1], 100)\n",
    "    X, Y = torch.meshgrid(X, Y, indexing='xy')\n",
    "    grid = torch.stack([m.flatten() for m in (X, Y)], dim=-1)\n",
    "    function_plot = objective_function(grid).reshape(X.shape)\n",
    "    #Set up initial sampling process, x in [min, max] and then calculate corresponding y\n",
    "    init_x = (Wrapper.bounds[1][0] - Wrapper.bounds[0][0]) * torch.rand((20,2), dtype=torch.float64) + Wrapper.bounds[0][0]\n",
    "    init_y = objective_function(init_x).unsqueeze(-1)\n",
    "    model = SingleTaskGP(train_X=init_x, train_Y=init_y)\n",
    "    dims, tol = 2, 0.05\n",
    "    frames = []\n",
    "    regret = list()\n",
    "    for i in range(1, frame_num+1):\n",
    "        \n",
    "        #mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model)\n",
    "        #fit_gpytorch_mll(mll)\n",
    "        #Preliminaries for optimization, initiate the acquisition function and find the max\n",
    "        beta = beta_coeff * np.log(i)\n",
    "        acquisition_function = botorch.acquisition.analytic.UpperConfidenceBound(model, beta, maximize=True)\n",
    "    \n",
    "        candidates, acquisition_value = optimize_acqf(acq_function=acquisition_function,\n",
    "                                                      bounds = torch.tensor(Wrapper.bounds),\n",
    "                                                      q=1,\n",
    "                                                      num_restarts=10,\n",
    "                                                      raw_samples=512,\n",
    "                                                      options={\"batch_limit\": 5, \"maxiter\": 100})\n",
    "        regret.append(Wrapper.maximum - init_y[-1].detach().item())\n",
    "        #attaches a frame to frames to save at the end\n",
    "        buffer = io.BytesIO()\n",
    "        make_frame(frames, function_plot, X, Y, model, init_y, beta, i, regret, Wrapper.name, grid)\n",
    "        #prepares model for next iteration\n",
    "        next_result = (objective_function(candidates[0])).unsqueeze(-1)\n",
    "        model = model.condition_on_observations(candidates.to(torch.float64), next_result.to(torch.float64))\n",
    "        init_y = torch.cat((init_y, next_result.unsqueeze(-1)), dim=0)\n",
    "        \n",
    "    os.makedirs(os.path.dirname(f'figures/{Wrapper.name}/'), exist_ok=True)\n",
    "    frames[0].save(f'figures/{Wrapper.name}/{Wrapper.name}_beta_{beta_coeff}.gif', save_all=True, append_images=frames[1:], duration=500, loop=0)"
   ],
   "id": "80977ad65714876",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:49:45.685793Z",
     "start_time": "2025-02-26T19:49:45.683952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_betas(Wrapper):\n",
    "    for beta in [0.1, 0.3, 1, 5, 10, 30, 50, 100]:\n",
    "        make_graph(Wrapper, beta)"
   ],
   "id": "91c8e276a3779204",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:49:45.688012Z",
     "start_time": "2025-02-26T19:49:45.686547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wrappers = [SumSquares] #already tested: Michalewicz, Rastigrin, Six_Hump, Bukin6, StyblinskiTang, GoldsteinPrice, McCormick, \n",
    "# for wrapper in wrappers:\n",
    "#     test_betas(wrapper)"
   ],
   "id": "571c551569818896",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:59:03.808292Z",
     "start_time": "2025-02-26T19:49:45.688552Z"
    }
   },
   "cell_type": "code",
   "source": "test_betas(GoldsteinPrice)",
   "id": "30710675309d321a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/var/folders/vk/38fbwqvx4dg05k8q97qj8qfm0000gn/T/ipykernel_1980/3474301153.py:22: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(buf, format='png')\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/josecruz/anaconda3/envs/GPR/lib/python3.11/site-packages/botorch/models/utils/assorted.py:265: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/var/folders/vk/38fbwqvx4dg05k8q97qj8qfm0000gn/T/ipykernel_1980/3474301153.py:22: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(buf, format='png')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:59:03.811610Z",
     "start_time": "2025-02-26T19:59:03.809545Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "69e926fd8e393015",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
