{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T18:38:58.905039Z",
     "start_time": "2025-02-05T18:38:56.785933Z"
    }
   },
   "source": [
    "import botorch.acquisition\n",
    "import torch\n",
    "import numpy\n",
    "from NNTraining import k_fold_training, PandasDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import botorch as bt\n",
    "import numpy as np\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.constraints import GreaterThan\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition.analytic import LogExpectedImprovement\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "import gpytorch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:38:58.916759Z",
     "start_time": "2025-02-05T18:38:58.905950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading dataset\n",
    "dataset = pd.read_csv('iris.csv', names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n",
    "feature_cols = [col for col in dataset.columns]\n",
    "feature_cols.remove('class')\n",
    "dataset"
   ],
   "id": "f0a8c7b7e358bdb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:44:24.872255Z",
     "start_time": "2025-02-05T18:44:24.852443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = list(dataset['class'].unique())\n",
    "# for col in feature_cols:\n",
    "#     #normalize dataset\n",
    "#     dataset[col] = (dataset[col] - dataset[col].mean())/(dataset[col].std())\n",
    "#set feature and class names\n",
    "dataset['class'] = dataset['class'].map({species:i for i, species in enumerate(class_names)})\n",
    "#print(dataset.head)\n",
    "#turn into training-friendly pytorch dataset format\n",
    "dataset = PandasDataset(dataset, feature_cols, 'class')"
   ],
   "id": "2e916eff492f7ac7",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m class_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# for col in feature_cols:\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#     #normalize dataset\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#     dataset[col] = (dataset[col] - dataset[col].mean())/(dataset[col].std())\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#set feature and class names\u001B[39;00m\n\u001B[1;32m      6\u001B[0m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap({species:i \u001B[38;5;28;01mfor\u001B[39;00m i, species \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(class_names)})\n",
      "File \u001B[0;32m~/Desktop/S25 Files/Lab/Code/NNTraining.py:102\u001B[0m, in \u001B[0;36mPandasDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m--> 102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures[idx]), torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[idx])\n",
      "\u001B[0;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:38:58.922410Z",
     "start_time": "2025-02-05T18:38:58.920982Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b0d253a8f06ea5b8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:38:59.083659Z",
     "start_time": "2025-02-05T18:38:59.078825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective_function(hyperparams):\n",
    "    hyperparams[hyperparams==0] += 1e-10\n",
    "    topology = torch.ceil(30 * hyperparams[0:4]).int() #first 4 params are topological structure\n",
    "    batch_size = torch.ceil((hyperparams[4] + 1e-8) * 128).int()\n",
    "    learning_rate = hyperparams[5]\n",
    "    accs = k_fold_training(dataset, 4, topology, 3, stratified=True, epochs=50, k=10, batch_size=int(batch_size), learning_rate=learning_rate)\n",
    "    return np.mean(accs)\n",
    "\n",
    "def GPUCB_function(t: int, model, error):\n",
    "    '''Generate relevant GPUCB parameters, return mu + beta_t sigma for the model'''\n",
    "    #train inputs are a tuple of the form (inputs,...), so access inputs and then get the shape of the first one\n",
    "    dims = len(model.train_inputs[0][0])\n",
    "    grid = torch.meshgrid(*[torch.linspace(1e-10,1,100) for _ in range(dims)], indexing='xy')\n",
    "    grid = torch.stack([m.flatten() for m in grid], dim=-1)\n",
    "    distribution = model(grid) #evaluates the model at every point in the grid and returns the distribution\n",
    "    # mu = distribution.mean.unsqueeze(-1) #gets the mean at every point and reshapes to grid shape\n",
    "    # sigma = distribution.variance.unsqueeze(-1)\n",
    "    kernel = model.covar_module\n",
    "    train_points = model.train_inputs[0]\n",
    "    covariance_matrix = kernel(train_points).to_dense() + torch.eye(train_points.shape[0]) * 1e2 #adds noise \n",
    "    k_matrix = kernel(train_points, grid.unsqueeze(1)).to_dense()\n",
    "    mu = k_matrix.transpose(1,2) @ torch.linalg.solve(covariance_matrix, init_y)\n",
    "    mu = mu_t.squeeze()\n",
    "    sigma = kernel(grid.unsqueeze(1), grid.unsqueeze(1)).to_dense().squeeze() #variance of every point with itself\n",
    "    sigma -= (k_matrix.transpose(1,2) @ torch.linalg.solve(covariance_matrix, k_matrix)).squeeze() #noise value\n",
    "    beta = 2*np.log((dims * t**2 * torch.pi**2)/(6*error))\n",
    "    \n",
    "    max_arg = torch.argmax(mu + torch.sqrt(sigma*beta))\n",
    "    return grid[max_arg]\n"
   ],
   "id": "87af57a9ca122a0d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:41:38.920330Z",
     "start_time": "2025-02-05T18:41:38.858099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Do initial runs\n",
    "init_x = torch.rand(size = (20,6), dtype = torch.float64)\n",
    "init_y = torch.tensor(list(map(objective_function, init_x))).unsqueeze(-1)"
   ],
   "id": "7ac503266df045bc",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Do initial runs\u001B[39;00m\n\u001B[1;32m      2\u001B[0m init_x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m20\u001B[39m,\u001B[38;5;241m6\u001B[39m), dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m----> 3\u001B[0m init_y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(objective_function, init_x)))\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m, in \u001B[0;36mobjective_function\u001B[0;34m(hyperparams)\u001B[0m\n\u001B[1;32m      4\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mceil((hyperparams[\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-8\u001B[39m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m128\u001B[39m)\u001B[38;5;241m.\u001B[39mint()\n\u001B[1;32m      5\u001B[0m learning_rate \u001B[38;5;241m=\u001B[39m hyperparams[\u001B[38;5;241m5\u001B[39m]\n\u001B[0;32m----> 6\u001B[0m accs \u001B[38;5;241m=\u001B[39m k_fold_training(dataset, \u001B[38;5;241m4\u001B[39m, topology, \u001B[38;5;241m3\u001B[39m, stratified\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(batch_size), learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(accs)\n",
      "File \u001B[0;32m~/Desktop/S25 Files/Lab/Code/NNTraining.py:82\u001B[0m, in \u001B[0;36mk_fold_training\u001B[0;34m(dataset, input_size, hidden_sizes, output_size, k, epochs, batch_size, learning_rate, stratified)\u001B[0m\n\u001B[1;32m     79\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlearning_rate)\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m---> 82\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train_model(model, train_loader, criterion, optimizer, device)\n\u001B[1;32m     83\u001B[0m     val_loss, val_accuracy \u001B[38;5;241m=\u001B[39m validate_model(model, val_loader, criterion, device)\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;66;03m#if epoch % 10 == 0:\u001B[39;00m\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;66;03m#print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Accuracy = {val_accuracy:.4f}\")\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/S25 Files/Lab/Code/NNTraining.py:33\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, criterion, optimizer, device)\u001B[0m\n\u001B[1;32m     30\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     32\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 33\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[1;32m     34\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     35\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/S25 Files/Lab/Code/NNTraining.py:23\u001B[0m, in \u001B[0;36mNeuralNetwork.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetwork(x)\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/anaconda3/envs/GPR/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T15:52:34.032887Z",
     "start_time": "2025-02-05T15:52:33.192400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#do 20 more runs with gp\n",
    "model = SingleTaskGP(train_X=init_x, train_Y=init_y)\n",
    "dims, tol = 6, 0.05\n",
    "for i in range(1, 60+1):\n",
    "    #model.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n",
    "    mll = ExactMarginalLogLikelihood(likelihood=model.likelihood, model=model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    #acquisition_function = LogExpectedImprovement(model=model, best_f=max(init_y), maximize=True)\n",
    "    beta = 2*np.log((dims * i**2 * torch.pi**2)/(6*tol))\n",
    "    acquisition_function = botorch.acquisition.analytic.UpperConfidenceBound(model, beta/5)\n",
    "\n",
    "    candidates, acquisition_value = optimize_acqf(acq_function=acquisition_function,\n",
    "                                          bounds = torch.tensor([[0. for _ in range(dims)], [1. for _ in range(dims)]]),\n",
    "                                          q=1,\n",
    "                                          num_restarts=20,\n",
    "                                          raw_samples=1024,\n",
    "                                          options={\"batch_limit\": 5, \"maxiter\": 200})\n",
    "    #print(candidates[0])\n",
    "    next_result = torch.tensor(objective_function(candidates[0])).unsqueeze(-1)\n",
    "    model = model.condition_on_observations(candidates.to(torch.float64), next_result)\n",
    "    init_y = torch.cat((init_y, next_result.unsqueeze(-1)), dim=0)\n",
    "        "
   ],
   "id": "64ac407bac8ea2cc",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SingleTaskGP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#do 20 more runs with gp\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m SingleTaskGP(train_X\u001B[38;5;241m=\u001B[39minit_x, train_Y\u001B[38;5;241m=\u001B[39minit_y)\n\u001B[1;32m      3\u001B[0m dims, tol \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m0.05\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m60\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m#model.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'SingleTaskGP' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T02:57:24.871621Z",
     "start_time": "2025-01-31T02:57:24.852207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hyperparams=model.train_inputs[0][torch.argmax(init_y)]\n",
    "topology = torch.ceil(30 * hyperparams[0:4]).int() #first 4 params are topological structure\n",
    "batch_size = torch.ceil((hyperparams[4] + 1e-8) * 128).int()\n",
    "learning_rate = hyperparams[5]\n",
    "print(topology, batch_size, learning_rate, torch.max(init_y))"
   ],
   "id": "ce55c2c3d8ace172",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([26, 18, 27, 12], dtype=torch.int32) tensor(104, dtype=torch.int32) tensor(0.0152, dtype=torch.float64) tensor(0.9800, dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-30T17:17:33.528153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dims = len(model.train_inputs[0][0])\n",
    "grid = torch.meshgrid(*[torch.linspace(0,1,100) for _ in range(dims)], indexing='xy')\n",
    "grid = torch.stack([m.flatten() for m in grid], dim=-1)\n",
    "distribution = model(grid) #evaluates the model at every point in the grid and returns the distribution\n",
    "mu = distribution.mean\n",
    "sigma_t = distribution.stddev\n",
    "t, error = (20, 0.05)\n",
    "beta_t = 2*np.log((dims * t**2 * torch.pi**2)/(6*error))\n",
    "max_arg = torch.argmax(mu + sigma_t*beta_t)\n",
    "kernel = model.covar_module\n",
    "train_points = model.train_inputs[0]\n",
    "covariance_matrix = kernel(train_points).to_dense() + torch.eye(train_points.shape[0]) * 1e-8 #adds noise \n",
    "k_matrix = kernel(train_points, grid.unsqueeze(1)).to_dense()\n",
    "mu_t = k_matrix.transpose(1,2) @ torch.linalg.solve(covariance_matrix, init_y)\n",
    "mu_t = mu_t.squeeze()\n",
    "grid_covariance = kernel(grid.unsqueeze(1), grid.unsqueeze(1)).to_dense().squeeze() #variance of every point with itself\n",
    "grid_covariance -= (k_matrix.transpose(1,2) @ torch.linalg.solve(covariance_matrix, k_matrix)).squeeze() #noise value\n",
    "gpucb_max = torch.argmax(mu_t + grid_covariance*beta_t)\n",
    "print(grid[max_arg],grid[gpucb_max])"
   ],
   "id": "683cb60f6b1be701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sigma = kernel(grid.unsqueeze(1), grid.unsqueeze(1)).to_dense()\n",
    "sigma = sigma.squeeze()\n",
    "init_y"
   ],
   "id": "aa18d518be3c8677",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "covariance_matrix.diag() + 1e-4",
   "id": "b4a8de73383cf508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#GPUCB(1,model,0.05)\n",
    "dims = len(model.train_inputs[0][0])\n",
    "grid = torch.meshgrid(*[torch.linspace(0,1,100) for _ in range(dims)], indexing='xy')\n",
    "grid = torch.stack([m.flatten() for m in grid], dim=-1)\n",
    "distribution = model(grid) #evaluates the model at every point in the grid and returns the distribution\n",
    "mu = distribution.mean.unsqueeze(-1) #gets the mean at every point and reshapes to grid shape\n",
    "# sigma = distribution.variance.unsqueeze(-1)\n",
    "# beta = 2*torch.log((dims * t**2 * torch.pi**2)/(6*error))\n"
   ],
   "id": "79ce4f0db18417af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel = gpytorch.kernels.RBFKernel()\n",
    "kernel(grid[0:5], grid[0:5]).to_dense()"
   ],
   "id": "b2a67615667f8b9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b46c28daeb397d38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4c5a8e34608256d6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
